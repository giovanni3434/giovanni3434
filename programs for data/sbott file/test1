import re
import json
import random
import nltk
# nltk.download('stopwords')
# nltk.download('punkt')
# nltk.download('wordnet')
# nltk.download('omw-1.4')
import transformers
import openai
from transformers import GPT2Tokenizer, GPT2LMHeadModel
from nltk.stem import WordNetLemmatizer
from nltk.corpus import stopwords
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

openai.api_key = "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"


class SolarSalesBot:
    def __init__(self):
        # Load the JSON files
        with open('intents.json', 'r') as f:
            intents = json.load(f)
        with open('prompts.json', 'r') as f:
            prompts = json.load(f)

        # Extract the data from the JSON files (intents.json , prompts.json)
        self.intents = {intent_name: keywords for intent_name,
                        keywords in intents.items()}
        self.solar_energy_prompt = prompts["solar_energy_prompts"]

        self.lemmatizer = nltk.WordNetLemmatizer()
        self.stopwords = nltk.corpus.stopwords.words('english')
        self.negative_responses = (
            "no", "nope", "nah", "naw", "not a chance", "sorry")
        self.exit_commands = ("quit", "pause", "exit",
                              "goodbye", "bye", "later")
        self.random_questions = (
            "Why are you interested in solar? ",
            "Tell me more about your interests in solar, benefits, tech, etc ")

        # Load the GPT-2 model and tokenizer
        self.model = GPT2LMHeadModel.from_pretrained('gpt2')
        self.tokenizer = GPT2Tokenizer.from_pretrained('gpt2')

    def greet(self):
        name = input("Hi, what's your name?")
        will_help = input(
            f"Hi {name}, I'm Sbott. I'm your solar consultant. Do you need help to go Solar?")
        if will_help.lower() in self.negative_responses or will_help.lower() in self.exit_commands:
            print("Ok, have a nice day!")
            return

        is_homeowner = input("Are you a homeowner?").lower()
        if not re.match(r'(?:yes|y(?:eah)?)', is_homeowner):
            print("We are sorry, you broke fuck!")
            return
        self.chat()

    def make_exit(self, reply):
        for exit_command in self.exit_commands:
            if reply == exit_command:
                print("Ok, have a nice day!")
                return True
        return False

    def chat(self):
        reply = input(random.choice(self.random_questions)).lower()
        while not self.make_exit(reply):
            reply = input(self.match_reply(reply))

    def match_reply(self, reply):
        tokens = nltk.word_tokenize(reply)
        lemmas = [self.lemmatizer.lemmatize(token) for token in tokens]
        filtered_lemmas = [lemma for lemma in lemmas if lemma not in self.stopwords]

    # Read the responses from the responses.json file
        with open("responses.json", "r") as f:
            responses = json.load(f)

    # Check if any of the keywords associated with the intents are present in the user's input
        for intent_name, keywords in self.intents.items():
            for keyword in keywords:
                if keyword in filtered_lemmas:
                    response = responses[intent_name]
                    if isinstance(response, tuple):
                        return random.choice(response)
                    return response

        concepts = self.extract_concepts(reply)

        most_similar_prompt = None
        highest_similarity = 0
        for prompt in self.solar_energy_prompt:
            if reply.lower() == prompt.lower():
                return self.generate_response(prompt)

            similarity = self.calculate_similarity(concepts, prompt)
            if similarity > highest_similarity:
                most_similar_prompt = prompt
                highest_similarity = similarity

        if most_similar_prompt is not None:
            response = self.generate_response(most_similar_prompt)
            return response

        response = self.generate_response(reply)
        return response


    def extract_concepts(self, reply):
        tokens = nltk.word_tokenize(reply)
        
        lemmatizer = nltk.WordNetLemmatizer()
        lemmas = [lemmatizer.lemmatize(token) for token in tokens if token not in self.stopwords]
        
        grammar = r"""  NP: {<DT>?<JJ>*<NN>} """
        cp = nltk.RegexpParser(grammar)
        tree = cp.parse(nltk.pos_tag(lemmas))
        concepts = []
        for subtree in tree:
            if isinstance(subtree, nltk.Tree) and subtree.label() == 'NP':
                concept = " ".join([word for word, pos in subtree])
                concepts.append(concept)
                
        return " ".join(concepts)

    def calculate_similarity(self, concepts, prompt):
        # Initialize the vectorizer
        vectorizer = TfidfVectorizer()

        # Tokenize and lemmatize the prompt
        tokens = nltk.word_tokenize(prompt)
        lemmatizer = nltk.WordNetLemmatizer()
        lemmas = [lemmatizer.lemmatize(
            token) for token in tokens if token not in self.stopwords]

        # Vectorize the concepts and the prompt
        vectors = vectorizer.fit_transform([concepts, " ".join(lemmas)])

        # Calculate the cosine similarity between the vectors
        similarity = cosine_similarity(vectors[0], vectors[1])
        return similarity[0][0]

    # Use the GPT-2 model to generate a response
    def generate_response(self, reply):
        message = openai.Completion.create(
            engine="text-davinci-002", prompt=f"{reply}\n{self.solar_energy_prompt}", max_tokens=250, n=1, stop=None, temperature=0.5).choices[0].text
        return message


Chatbot = SolarSalesBot()
Chatbot.greet()
